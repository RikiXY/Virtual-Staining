{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizioni e caricamenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento dei moduli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni di aiuto matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STD_FIGSIZE = (20, 20)\n",
    "\n",
    "def to_plot(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_image(image, title, cmap=None, figsize=STD_FIGSIZE):\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    subplot = figure.add_subplot(1, 1, 1)\n",
    "    subplot.set_title(title)\n",
    "    subplot.axis('off')\n",
    "    subplot.imshow(image, cmap=cmap)\n",
    "\n",
    "def show_side_images(image_1, title_1, image_2, title_2, cmap=None, figsize=STD_FIGSIZE):\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    subplots = figure.subplots(1, 2)\n",
    "    figure.subplots_adjust(wspace=0.01)\n",
    "    subplots[0].set_title(title_1)\n",
    "    subplots[0].axis('off')\n",
    "    subplots[0].imshow(image_1, cmap=cmap)\n",
    "    subplots[1].set_title(title_2)\n",
    "    subplots[1].axis('off')\n",
    "    subplots[1].imshow(image_2, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni di aiuto OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import DMatch\n",
    "\n",
    "DEF_NFEATURES = 10000\n",
    "DEF_SIFT_NFEATURES = DEF_NFEATURES\n",
    "DEF_ORB_NFEATURES = DEF_NFEATURES\n",
    "DEF_FILTER_DISTANCE = 20\n",
    "DEF_LOWES_RATIO = 0.75\n",
    "\n",
    "def convert_to_gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def equalize_image(image):\n",
    "    return cv2.equalizeHist(image)\n",
    "\n",
    "def apply_clahe(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    output_image = clahe.apply(image)\n",
    "    return output_image\n",
    "\n",
    "def blur_image(image, strength=5):\n",
    "    return cv2.GaussianBlur(image, (strength, strength), 0)\n",
    "\n",
    "def compute_ecc_transform(image_1, image_2):\n",
    "    # Initialize the warp matrix\n",
    "    warp_mode = cv2.MOTION_TRANSLATION\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    # Set the stopping criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-10)\n",
    "\n",
    "    # Run the ECC algorithm\n",
    "    cc, warp_matrix = cv2.findTransformECC(image_1, image_2, warp_matrix, warp_mode, criteria)\n",
    "    return warp_matrix\n",
    "\n",
    "def apply_ecc_transform(image, warp_matrix, shape=None):\n",
    "    if shape is None:\n",
    "        h, w = image.shape[:2]\n",
    "    else:\n",
    "        h, w = shape[:2]\n",
    "    output_image = cv2.warpAffine(image, warp_matrix, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    return output_image\n",
    "\n",
    "def filter_matches_with_lowes_ratio(matches: list[DMatch], threshold=DEF_LOWES_RATIO):\n",
    "    filtered_matches = []\n",
    "    for m in matches:\n",
    "        if len(m) == 2 and m[0].distance < threshold * m[1].distance:\n",
    "            filtered_matches.append(m[0])\n",
    "    return filtered_matches\n",
    "\n",
    "def compute_sift_matches(image_1, image_2, nfeatures=DEF_SIFT_NFEATURES, use_lowes_ratio=False):\n",
    "    sift = cv2.SIFT_create(nfeatures=nfeatures)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=not use_lowes_ratio)\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints_1, descriptors_1 = sift.detectAndCompute(image_1, None)\n",
    "    keypoints_2, descriptors_2 = sift.detectAndCompute(image_2, None)\n",
    "\n",
    "    # Match descriptors\n",
    "    if use_lowes_ratio:\n",
    "        matches = bf.knnMatch(descriptors_1, descriptors_2, k=2)\n",
    "        matches = filter_matches_with_lowes_ratio(matches)\n",
    "    else:\n",
    "        matches = bf.match(descriptors_1, descriptors_2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches, (keypoints_1, keypoints_2)\n",
    "\n",
    "def compute_orb_matches(image_1, image_2, nfeatures=DEF_ORB_NFEATURES, use_lowes_ratio=False):\n",
    "    orb = cv2.ORB_create(nfeatures=nfeatures)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=not use_lowes_ratio)\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints_1, descriptors_1 = orb.detectAndCompute(image_1, None)\n",
    "    keypoints_2, descriptors_2 = orb.detectAndCompute(image_2, None)\n",
    "\n",
    "    # Match descriptors\n",
    "    if use_lowes_ratio:\n",
    "        matches = bf.knnMatch(descriptors_1, descriptors_2, k=2)\n",
    "        matches = filter_matches_with_lowes_ratio(matches)\n",
    "    else:\n",
    "        matches = bf.match(descriptors_1, descriptors_2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches, (keypoints_1, keypoints_2)\n",
    "\n",
    "def extract_points(matches: list[DMatch], keypoints: tuple[list, list]):\n",
    "    points = ([], [])\n",
    "    for m in matches:\n",
    "        points[0].append(keypoints[0][m.queryIdx].pt)\n",
    "        points[1].append(keypoints[1][m.trainIdx].pt)\n",
    "    return points\n",
    "\n",
    "def filter_matches_by_euclidean_distance(matches: list[DMatch], keypoints: tuple[list, list], distance=DEF_FILTER_DISTANCE):\n",
    "    filtered_matches = []\n",
    "    for m in matches:\n",
    "        euclidean_distance = np.linalg.norm(np.array(keypoints[0][m.queryIdx].pt) - np.array(keypoints[1][m.trainIdx].pt))\n",
    "        if euclidean_distance < distance:\n",
    "            filtered_matches.append(m)\n",
    "    return filtered_matches\n",
    "\n",
    "def compute_ransac_transform(points_1, points_2):\n",
    "    points_1 = np.float32(points_1).reshape(-1,1,2)\n",
    "    points_2 = np.float32(points_2).reshape(-1,1,2)\n",
    "    H, mask = cv2.findHomography(points_2, points_1, cv2.RANSAC, 10.0)\n",
    "    return H\n",
    "\n",
    "def apply_ransac_transform(image, warp_matrix, shape=None):\n",
    "    if shape is None:\n",
    "        h, w = image.shape[:2]\n",
    "    else:\n",
    "        h, w = shape[:2]\n",
    "    output_image = cv2.warpPerspective(image, warp_matrix, (w, h))\n",
    "    return output_image\n",
    "\n",
    "def compute_countours(image, threshold1=50, threshold2=150):\n",
    "    edges = cv2.Canny(image, threshold1=threshold1, threshold2=threshold2)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apertura delle immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_free_path = \"../Materiale/Prove/non_colorato.png\"\n",
    "stained_path = \"../Materiale/Prove/colorato.png\"\n",
    "\n",
    "label_free = cv2.imread(label_free_path)\n",
    "stained = cv2.imread(stained_path)\n",
    "\n",
    "label_free_gray = convert_to_gray(label_free)\n",
    "stained_gray = convert_to_gray(stained)\n",
    "\n",
    "label_free_equalized = equalize_image(label_free_gray)\n",
    "stained_equalized = equalize_image(stained_gray)\n",
    "\n",
    "label_free_clahe = apply_clahe(label_free_gray)\n",
    "stained_clahe = apply_clahe(stained_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immagini iniziali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(stained), \"Colorata\")\n",
    "show_side_images(label_free_gray, \"Non colorata grigio\", stained_gray, \"Colorata grigio\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata equalizzata\", stained_equalized, \"Colorata equalizzata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata CLAHE\", stained_clahe, \"Colorata CLAHE\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allineamento con ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_matrix = compute_ecc_transform(label_free_equalized, stained_equalized)\n",
    "aligned_stained = apply_ecc_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "\n",
    "difference_og = cv2.absdiff(label_free_equalized, stained_equalized)\n",
    "difference_aligned = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(difference_og, \"Differenza assoluta tra immagini originali\", difference_aligned, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento tramite Feature Matching con SIFT e immagini originali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, keypoints = compute_sift_matches(label_free, stained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtraggio dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_matches = cv2.drawMatches(\n",
    "    label_free, keypoints[0],\n",
    "    stained, keypoints[1],\n",
    "    filtered_matches,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    matchesThickness=5\n",
    ")\n",
    "print(f\"Matches: {len(filtered_matches)}\")\n",
    "show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allineamento dell'immagine con RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = extract_points(filtered_matches, keypoints)\n",
    "warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "aligned_stained = apply_ransac_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "aligned_stained_clahe = apply_clahe(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata\", aligned_stained_clahe, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento tramite Feature Matching con SIFT e immagini monocromatiche non equalizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, keypoints = compute_sift_matches(label_free_gray, stained_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtraggio dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_matches = cv2.drawMatches(\n",
    "    label_free, keypoints[0],\n",
    "    stained, keypoints[1],\n",
    "    filtered_matches,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    matchesThickness=5\n",
    ")\n",
    "print(f\"Matches: {len(filtered_matches)}\")\n",
    "show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allineamento dell'immagine con RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = extract_points(filtered_matches, keypoints)\n",
    "warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "aligned_stained = apply_ransac_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "aligned_stained_clahe = apply_clahe(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata\", aligned_stained_clahe, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento tramite Feature Matching con SIFT e immagini monocromatiche equalizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, keypoints = compute_sift_matches(label_free_equalized, stained_equalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtraggio dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_matches = cv2.drawMatches(\n",
    "    label_free, keypoints[0],\n",
    "    stained, keypoints[1],\n",
    "    filtered_matches,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    matchesThickness=5\n",
    ")\n",
    "print(f\"Matches: {len(filtered_matches)}\")\n",
    "show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allineamento dell'immagine con RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = extract_points(filtered_matches, keypoints)\n",
    "warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "aligned_stained = apply_ransac_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "aligned_stained_clahe = apply_clahe(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata\", aligned_stained_clahe, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento tramite Feature Matching con SIFT e immagini monocromatiche CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, keypoints = compute_sift_matches(label_free_clahe, stained_clahe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtraggio dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_matches = cv2.drawMatches(\n",
    "    label_free, keypoints[0],\n",
    "    stained, keypoints[1],\n",
    "    filtered_matches,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    matchesThickness=5\n",
    ")\n",
    "print(f\"Matches: {len(filtered_matches)}\")\n",
    "show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allineamento dell'immagine con RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = extract_points(filtered_matches, keypoints)\n",
    "warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "aligned_stained = apply_ransac_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "aligned_stained_clahe = apply_clahe(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata\", aligned_stained_clahe, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crea GIF (temporaneo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "# Define parameters\n",
    "duration = 0.5  # seconds\n",
    "frames = 2\n",
    "fps = frames / duration\n",
    "\n",
    "fig, ax = plt.subplots(figsize=STD_FIGSIZE)\n",
    "ax.axis('off')\n",
    "\n",
    "# Initialize with fully transparent aligned_stained (alpha=0)\n",
    "blend_init = cv2.addWeighted(label_free, 1.0, aligned_stained, 0.0, 0)\n",
    "im = ax.imshow(cv2.cvtColor(blend_init, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def update(frame):\n",
    "    alpha = 0 if frame == 0 else 1\n",
    "    blended = cv2.addWeighted(label_free, 1 - alpha, aligned_stained, alpha, 0)\n",
    "    im.set_data(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=frames, interval=1000/fps, blit=True)\n",
    "ani.save('fade.gif', writer='pillow', fps=fps)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contorni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength = 1\n",
    "blur_label_free = blur_image(label_free_gray, strength=strength)\n",
    "blur_stained = blur_image(stained_gray, strength=strength)\n",
    "blur_aligned_stained = blur_image(aligned_stained_gray, strength=strength)\n",
    "\n",
    "# 5. Create a black background\n",
    "height, width = label_free_gray.shape\n",
    "contour_mask_blur_label_free = np.zeros((height, width), dtype=np.uint8)\n",
    "contour_mask_blur_stained = np.zeros((height, width), dtype=np.uint8)\n",
    "contour_mask_blur_aligned_stained = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "# 6. Draw contours in white\n",
    "cv2.drawContours(contour_mask_blur_label_free, compute_countours(blur_label_free), contourIdx=-1, color=255, thickness=1)\n",
    "cv2.drawContours(contour_mask_blur_stained, compute_countours(blur_stained), contourIdx=-1, color=255, thickness=1)\n",
    "cv2.drawContours(contour_mask_blur_aligned_stained, compute_countours(blur_aligned_stained), contourIdx=-1, color=255, thickness=1)\n",
    "\n",
    "intersection_original = cv2.bitwise_and(contour_mask_blur_label_free, contour_mask_blur_stained)\n",
    "intersection_aligned = cv2.bitwise_and(contour_mask_blur_label_free, contour_mask_blur_aligned_stained)\n",
    "\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata\", cmap='gray')\n",
    "show_side_images(contour_mask_blur_label_free, \"Contorni non colorata\", contour_mask_blur_stained, \"Contorni colorata\", cmap='gray')\n",
    "show_side_images(contour_mask_blur_label_free, \"Contorni non colorata\", contour_mask_blur_aligned_stained, \"Contorni colorata allineata\", cmap='gray')\n",
    "show_side_images(intersection_original, \"Intersezione contorni originali\", intersection_aligned, \"Intersezione contorni allineati\", cmap='gray')\n",
    "\n",
    "zoomed_countour_mask_1 = cv2.resize(label_free_gray, (0, 0), fx=2, fy=2)[800:1600, 800:1600]\n",
    "zoomed_countour_mask_2 = cv2.resize(aligned_stained_gray, (0, 0), fx=2, fy=2)[800:1600, 800:1600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "blur_label_free = cv2.GaussianBlur(label_free_gray, (5, 5), 0)\n",
    "blur_stained = cv2.GaussianBlur(stained_gray, (5, 5), 0)\n",
    "blur_aligned_stained = cv2.GaussianBlur(aligned_stained_gray, (5, 5), 0)\n",
    "\n",
    "score, diff_map = ssim(contour_mask_blur_label_free, contour_mask_blur_aligned_stained, full=True)\n",
    "print(\"SSIM:\", score)\n",
    "\n",
    "def mutual_information(image1, image2, bins=256):\n",
    "    \"\"\"\n",
    "    image1, image2: single-channel images (e.g., grayscale, same shape)\n",
    "    bins: number of intensity bins for the histogram\n",
    "    \"\"\"\n",
    "    # Flatten the images to 1D\n",
    "    i1 = image1.flatten()\n",
    "    i2 = image2.flatten()\n",
    "    \n",
    "    # Compute 2D joint histogram\n",
    "    joint_hist, x_edges, y_edges = np.histogram2d(i1, i2, bins=bins)\n",
    "    \n",
    "    # Convert to joint probability by dividing by total number of pixels\n",
    "    joint_prob = joint_hist / np.sum(joint_hist)\n",
    "    \n",
    "    # Marginal probabilities\n",
    "    p1 = np.sum(joint_prob, axis=1)  # sum over columns -> distribution of image1\n",
    "    p2 = np.sum(joint_prob, axis=0)  # sum over rows -> distribution of image2\n",
    "\n",
    "    # Avoid log(0) by adding small epsilon\n",
    "    eps = 1e-10\n",
    "    # MI formula\n",
    "    mi = 0.0\n",
    "    for i in range(bins):\n",
    "        for j in range(bins):\n",
    "            p_ij = joint_prob[i, j]\n",
    "            if p_ij > eps:\n",
    "                mi += p_ij * np.log(p_ij / (p1[i]*p2[j] + eps) + eps)\n",
    "\n",
    "    return mi\n",
    "\n",
    "mi_value = mutual_information(label_free, aligned_stained)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(label_free_gray, aligned_stained_gray)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(label_free_clahe, aligned_stained_clahe)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(blur_label_free, blur_stained)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(blur_label_free, blur_aligned_stained)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(contour_mask_blur_label_free, contour_mask_blur_aligned_stained)\n",
    "print(\"Mutual Information:\", mi_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento molteplico tramite Feature Matching con SIFT e immagini monocromatiche equalizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_stained = stained\n",
    "aligned_stained_equalized = stained_equalized\n",
    "\n",
    "N = 1\n",
    "\n",
    "for i in range(N):\n",
    "    matches, keypoints = compute_sift_matches(label_free_equalized, aligned_stained_equalized)\n",
    "    filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)\n",
    "\n",
    "    drawn_matches = cv2.drawMatches(\n",
    "        label_free, keypoints[0],\n",
    "        aligned_stained, keypoints[1],\n",
    "        filtered_matches,\n",
    "        None,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "        matchesThickness=5\n",
    "    )\n",
    "\n",
    "    print(f\"Matches: {len(filtered_matches)}\")\n",
    "    #show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")\n",
    "\n",
    "    points = extract_points(filtered_matches, keypoints)\n",
    "    warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "    print(i, warp_matrix)\n",
    "    aligned_stained = apply_ransac_transform(aligned_stained, warp_matrix, shape=label_free.shape)\n",
    "    aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "    aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_gray, aligned_stained_gray)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo con metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(img1: np.ndarray, img2: np.ndarray, bins: int = 256) -> float:\n",
    "    \"\"\"\n",
    "    Compute the mutual information (MI) between two grayscale images.\n",
    "    \n",
    "    :param img1: First image in grayscale.\n",
    "    :param img2: Second image in grayscale.\n",
    "    :param bins: Number of histogram bins to use (256 for 8-bit images).\n",
    "    :return: Mutual information (in bits) between img1 and img2.\n",
    "    \"\"\"\n",
    "    # Convert images to 1D numpy arrays (flatten) if they are not already\n",
    "    img1 = img1.ravel()\n",
    "    img2 = img2.ravel()\n",
    "\n",
    "    # Compute the joint histogram\n",
    "    # histogram2d returns the 2D histogram and bin edges\n",
    "    joint_hist, x_edges, y_edges = np.histogram2d(img1, img2, bins=bins)\n",
    "    \n",
    "    # Normalize the joint histogram to get the joint PDF p(x,y)\n",
    "    joint_pdf = joint_hist / np.sum(joint_hist)\n",
    "    \n",
    "    # Compute the marginal PDFs p(x) and p(y)\n",
    "    p_x = np.sum(joint_pdf, axis=1)  # Sum over columns -> marginal over x\n",
    "    p_y = np.sum(joint_pdf, axis=0)  # Sum over rows -> marginal over y\n",
    "\n",
    "    # Only consider non-zero values to avoid log(0)\n",
    "    # MI = sum p(x,y)*log( p(x,y)/(p(x)*p(y)) )\n",
    "    non_zero_idxs = joint_pdf > 0\n",
    "    mi = np.sum(joint_pdf[non_zero_idxs] * \n",
    "                np.log2(joint_pdf[non_zero_idxs] / \n",
    "                        (p_x[np.newaxis].T @ p_y[np.newaxis])[non_zero_idxs]))\n",
    "    \n",
    "    return mi\n",
    "\n",
    "MODE_SIFT = 0\n",
    "MODE_ORB = 1\n",
    "\n",
    "def align(image_1, image_2, image_to_align=None, image_to_confront=None, mode=MODE_SIFT, use_lowes_ratio=False):\n",
    "    if image_to_align is None:\n",
    "        image_to_align = image_2\n",
    "    if image_to_confront is None:\n",
    "        image_to_confront = image_1\n",
    "    if mode == MODE_SIFT:\n",
    "        matches, keypoints = compute_sift_matches(image_1, image_2, use_lowes_ratio=use_lowes_ratio)\n",
    "        print(f\"Matches: {len(matches)}\", end=\" - \")\n",
    "    elif mode == MODE_ORB:\n",
    "        matches, keypoints = compute_orb_matches(image_1, image_2, use_lowes_ratio=use_lowes_ratio)\n",
    "    else:\n",
    "        raise Exception(\"Mode not supported\")\n",
    "    filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)\n",
    "    points = extract_points(filtered_matches, keypoints)\n",
    "    warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "    aligned_image = apply_ransac_transform(image_to_align, warp_matrix, shape=image_1.shape)\n",
    "    blurred_aligned_image = blur_image(aligned_image, strength=1)\n",
    "    mi = mutual_information(image_to_confront, blurred_aligned_image)\n",
    "    return aligned_image, mi\n",
    "\n",
    "def test_all_colors(mode=MODE_SIFT, use_lowes_ratio=False):\n",
    "    mode = \"SIFT\" if mode == MODE_SIFT else \"ORB\"\n",
    "    _, mi = align(label_free_clahe, label_free_clahe, image_to_align=label_free_gray, image_to_confront=label_free_gray)\n",
    "    print(f\"{mode} - LR: {'T' if use_lowes_ratio else 'F'} - SAME - MI: {mi}\")\n",
    "    _, mi = align(label_free, stained, image_to_align=stained_gray, image_to_confront=label_free_gray)\n",
    "    print(f\"{mode} - LR: {'T' if use_lowes_ratio else 'F'} - ORIGINAL - MI: {mi}\")\n",
    "    _, mi = align(label_free_gray, stained_gray, image_to_align=stained_gray, image_to_confront=label_free_gray)\n",
    "    print(f\"{mode} - LR: {'T' if use_lowes_ratio else 'F'} - GRAY - MI: {mi}\")\n",
    "    _, mi = align(label_free_equalized, stained_equalized, image_to_align=stained_gray, image_to_confront=label_free_gray)\n",
    "    print(f\"{mode} - LR: {'T' if use_lowes_ratio else 'F'} - EQUALIZED - MI: {mi}\")\n",
    "    _, mi = align(label_free_clahe, stained_clahe, image_to_align=stained_gray, image_to_confront=label_free_gray)\n",
    "    print(f\"{mode} - LR: {'T' if use_lowes_ratio else 'F'} - CLAHE - MI: {mi}\")\n",
    "\n",
    "test_all_colors(mode=MODE_SIFT, use_lowes_ratio=False)\n",
    "test_all_colors(mode=MODE_SIFT, use_lowes_ratio=True)\n",
    "test_all_colors(mode=MODE_ORB, use_lowes_ratio=False)\n",
    "test_all_colors(mode=MODE_ORB, use_lowes_ratio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualStaining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
