{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizioni e caricamenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento dei moduli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni di aiuto matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STD_FIGSIZE = (20, 20)\n",
    "\n",
    "def to_plot(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_image(image, title, cmap=None, figsize=STD_FIGSIZE):\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    subplot = figure.add_subplot(1, 1, 1)\n",
    "    subplot.set_title(title)\n",
    "    subplot.axis('off')\n",
    "    subplot.imshow(image, cmap=cmap)\n",
    "\n",
    "def show_side_images(image_1, title_1, image_2, title_2, cmap=None, figsize=STD_FIGSIZE):\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    subplots = figure.subplots(1, 2)\n",
    "    figure.subplots_adjust(wspace=0.01)\n",
    "    subplots[0].set_title(title_1)\n",
    "    subplots[0].axis('off')\n",
    "    subplots[0].imshow(image_1, cmap=cmap)\n",
    "    subplots[1].set_title(title_2)\n",
    "    subplots[1].axis('off')\n",
    "    subplots[1].imshow(image_2, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni di aiuto OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funzioni semplici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def equalize_image(image):\n",
    "    return cv2.equalizeHist(image)\n",
    "\n",
    "def apply_clahe(image, clipLimit=2.0, tileGridSize=(8,8)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    output_image = clahe.apply(image)\n",
    "    return output_image\n",
    "\n",
    "def blur_image(image, strength=5):\n",
    "    return cv2.GaussianBlur(image, (strength, strength), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import DMatch\n",
    "\n",
    "DEF_FILTER_DISTANCE = 20\n",
    "DEF_LOWES_RATIO = 0.75\n",
    "\n",
    "def filter_matches_with_lowes_ratio(matches: list[DMatch], threshold=DEF_LOWES_RATIO):\n",
    "    filtered_matches = []\n",
    "    for m in matches:\n",
    "        if len(m) == 2 and m[0].distance < threshold * m[1].distance:\n",
    "            filtered_matches.append(m[0])\n",
    "    return filtered_matches\n",
    "\n",
    "# converto matches da tupla a lista (con i due punti) per utilizzi futuri, non per necessità attuale\n",
    "def filter_matches_by_euclidean_distance(matches: list[DMatch], keypoints: tuple[list, list], distance=DEF_FILTER_DISTANCE):\n",
    "    filtered_matches = []\n",
    "    for m in matches:\n",
    "        euclidean_distance = np.linalg.norm(np.array(keypoints[0][m.queryIdx].pt) - np.array(keypoints[1][m.trainIdx].pt))\n",
    "        if euclidean_distance < distance:\n",
    "            filtered_matches.append(m)\n",
    "    return filtered_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funzioni di match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import DMatch\n",
    "\n",
    "DEF_NFEATURES = 10000\n",
    "DEF_SIFT_NFEATURES = DEF_NFEATURES\n",
    "DEF_ORB_NFEATURES = DEF_NFEATURES\n",
    "\n",
    "def compute_sift_matches(image_1, image_2, nfeatures=DEF_SIFT_NFEATURES, use_lowes_ratio=False):\n",
    "    sift = cv2.SIFT_create(nfeatures=nfeatures)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=not use_lowes_ratio)\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints_1, descriptors_1 = sift.detectAndCompute(image_1, None)\n",
    "    keypoints_2, descriptors_2 = sift.detectAndCompute(image_2, None)\n",
    "\n",
    "    # Match descriptors\n",
    "    if use_lowes_ratio:\n",
    "        matches = bf.knnMatch(descriptors_1, descriptors_2, k=2)\n",
    "        matches = filter_matches_with_lowes_ratio(matches)\n",
    "    else:\n",
    "        matches = bf.match(descriptors_1, descriptors_2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches, (keypoints_1, keypoints_2)\n",
    "\n",
    "def compute_orb_matches(image_1, image_2, nfeatures=DEF_ORB_NFEATURES, use_lowes_ratio=False):\n",
    "    orb = cv2.ORB_create(nfeatures=nfeatures)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=not use_lowes_ratio)\n",
    "\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints_1, descriptors_1 = orb.detectAndCompute(image_1, None)\n",
    "    keypoints_2, descriptors_2 = orb.detectAndCompute(image_2, None)\n",
    "\n",
    "    # Match descriptors\n",
    "    if use_lowes_ratio:\n",
    "        matches = bf.knnMatch(descriptors_1, descriptors_2, k=2)\n",
    "        matches = filter_matches_with_lowes_ratio(matches)\n",
    "    else:\n",
    "        matches = bf.match(descriptors_1, descriptors_2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches, (keypoints_1, keypoints_2)\n",
    "\n",
    "def extract_points(matches: list[DMatch], keypoints: tuple[list, list]):\n",
    "    points = ([], [])\n",
    "    for m in matches:\n",
    "        points[0].append(keypoints[0][m.queryIdx].pt)\n",
    "        points[1].append(keypoints[1][m.trainIdx].pt)\n",
    "    return points\n",
    "\n",
    "def compute_ransac_transform(points_1, points_2):\n",
    "    points_1 = np.float32(points_1).reshape(-1,1,2)\n",
    "    points_2 = np.float32(points_2).reshape(-1,1,2)\n",
    "    H, mask = cv2.findHomography(points_2, points_1, cv2.RANSAC, 10.0)\n",
    "    return H\n",
    "\n",
    "def apply_ransac_transform(image, warp_matrix, shape=None):\n",
    "    if shape is None:\n",
    "        h, w = image.shape[:2]\n",
    "    else:\n",
    "        h, w = shape[:2]\n",
    "    output_image = cv2.warpPerspective(image, warp_matrix, (w, h))\n",
    "    return output_image\n",
    "\n",
    "def compute_ecc_transform(image_1, image_2):\n",
    "    # Initialize the warp matrix\n",
    "    warp_mode = cv2.MOTION_TRANSLATION\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    # Set the stopping criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-10)\n",
    "\n",
    "    # Run the ECC algorithm\n",
    "    cc, warp_matrix = cv2.findTransformECC(image_1, image_2, warp_matrix, warp_mode, criteria)\n",
    "    return warp_matrix\n",
    "\n",
    "def apply_ecc_transform(image, warp_matrix, shape=None):\n",
    "    if shape is None:\n",
    "        h, w = image.shape[:2]\n",
    "    else:\n",
    "        h, w = shape[:2]\n",
    "    output_image = cv2.warpAffine(image, warp_matrix, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Altre funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_countours(image, threshold1=50, threshold2=150):\n",
    "    edges = cv2.Canny(image, threshold1=threshold1, threshold2=threshold2)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apertura delle immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_free_path = \"../Materiale/Prove/non_colorato.png\"\n",
    "stained_path = \"../Materiale/Prove/colorato.png\"\n",
    "\n",
    "label_free = cv2.imread(label_free_path)\n",
    "stained = cv2.imread(stained_path)\n",
    "\n",
    "label_free_gray = convert_to_gray(label_free)\n",
    "stained_gray = convert_to_gray(stained)\n",
    "\n",
    "label_free_equalized = equalize_image(label_free_gray)\n",
    "stained_equalized = equalize_image(stained_gray)\n",
    "\n",
    "label_free_clahe = apply_clahe(label_free_gray, clipLimit=14.0, tileGridSize=(8, 8))\n",
    "stained_clahe = apply_clahe(stained_gray, clipLimit=14.0, tileGridSize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immagini iniziali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_side_images(to_plot(label_free), \"Non colorata\", to_plot(stained), \"Colorata\")\n",
    "# show_side_images(label_free_gray, \"Non colorata grigio\", stained_gray, \"Colorata grigio\", cmap='gray')\n",
    "# show_side_images(label_free_equalized, \"Non colorata equalizzata\", stained_equalized, \"Colorata equalizzata\", cmap='gray')\n",
    "# show_side_images(label_free_clahe, \"Non colorata CLAHE\", stained_clahe, \"Colorata CLAHE\", cmap='gray')\n",
    "\n",
    "figure, subplots = plt.subplots(4, 2, figsize=(10, 15))\n",
    "\n",
    "subplots[0, 0].imshow(label_free, cmap='gray')\n",
    "subplots[0, 0].set_title(\"Label Free Originale\")\n",
    "subplots[0, 0].axis(\"off\")\n",
    "subplots[1, 0].imshow(label_free_gray, cmap='gray')\n",
    "subplots[1, 0].set_title(\"Label Free Grayscale\")\n",
    "subplots[1, 0].axis(\"off\")\n",
    "subplots[2, 0].imshow(label_free_clahe, cmap='gray')\n",
    "subplots[2, 0].set_title(\"Label Free CLAHE\")\n",
    "subplots[2, 0].axis(\"off\")\n",
    "subplots[3, 0].imshow(label_free_equalized, cmap='gray')\n",
    "subplots[3, 0].set_title(\"Label Free equalizeHist\")\n",
    "subplots[3, 0].axis(\"off\")\n",
    "\n",
    "subplots[0, 1].imshow(stained, cmap='gray')\n",
    "subplots[0, 1].set_title(\"Stained Originale\")\n",
    "subplots[0, 1].axis(\"off\")\n",
    "subplots[1, 1].imshow(stained_gray, cmap='gray')\n",
    "subplots[1, 1].set_title(\"Stained Grayscale\")\n",
    "subplots[1, 1].axis(\"off\")\n",
    "subplots[2, 1].imshow(stained_clahe, cmap='gray')\n",
    "subplots[2, 1].set_title(\"Stained CLAHE\")\n",
    "subplots[2, 1].axis(\"off\")\n",
    "subplots[3, 1].imshow(stained_equalized, cmap='gray')\n",
    "subplots[3, 1].set_title(\"Stained equalizeHist\")\n",
    "subplots[3, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allineamento con ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_matrix = compute_ecc_transform(label_free_equalized, stained_equalized)\n",
    "aligned_stained = apply_ecc_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "\n",
    "difference_og = cv2.absdiff(label_free_equalized, stained_equalized)\n",
    "difference_aligned = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(difference_og, \"Differenza assoluta tra immagini originali\", difference_aligned, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento tramite Feature Matching con SIFT e immagini originali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, keypoints = compute_sift_matches(label_free, stained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtraggio dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_matches = cv2.drawMatches(\n",
    "    label_free, keypoints[0],\n",
    "    stained, keypoints[1],\n",
    "    filtered_matches,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    matchesThickness=5\n",
    ")\n",
    "print(f\"Matches: {len(filtered_matches)}\")\n",
    "show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allineamento dell'immagine con RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = extract_points(filtered_matches, keypoints)\n",
    "warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "aligned_stained = apply_ransac_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "aligned_stained_clahe = apply_clahe(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata\", aligned_stained_clahe, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento tramite Feature Matching con SIFT e immagini monocromatiche non equalizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, keypoints = compute_sift_matches(label_free_gray, stained_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtraggio dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_matches = cv2.drawMatches(\n",
    "    label_free, keypoints[0],\n",
    "    stained, keypoints[1],\n",
    "    filtered_matches,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    matchesThickness=5\n",
    ")\n",
    "print(f\"Matches: {len(filtered_matches)}\")\n",
    "show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allineamento dell'immagine con RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = extract_points(filtered_matches, keypoints)\n",
    "warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "aligned_stained = apply_ransac_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "aligned_stained_clahe = apply_clahe(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata\", aligned_stained_clahe, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento tramite Feature Matching con SIFT e immagini monocromatiche equalizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, keypoints = compute_sift_matches(label_free_equalized, stained_equalized)\n",
    "print(f\"SIFT matches with equalizeHist and .match() = {len(matches)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtraggio dei match\n",
    "\n",
    "#### Perchè mai filtrare? stai usando crossCheck=True?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)\n",
    "print(f\"SIFT matches with CLAHE and .match() + Filter (distanza euclidea) = {len(filtered_matches)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_matches = cv2.drawMatches(\n",
    "    label_free, keypoints[0],\n",
    "    stained, keypoints[1],\n",
    "    filtered_matches,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    matchesThickness=5\n",
    ")\n",
    "print(f\"Matches: {len(filtered_matches)}\")\n",
    "show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allineamento dell'immagine con RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = extract_points(filtered_matches, keypoints)\n",
    "warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "aligned_stained = apply_ransac_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "aligned_stained_clahe = apply_clahe(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata\", aligned_stained_clahe, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allinamento tramite Feature Matching con SIFT e immagini monocromatiche CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, keypoints = compute_sift_matches(label_free_clahe, stained_clahe)\n",
    "print(f\"SIFT con CLAHE e .match(): {len(matches)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtraggio dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)\n",
    "print(f\"SIFT con CLAHE e .match() e filtro euclideo: {len(filtered_matches)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dei match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_matches = cv2.drawMatches(\n",
    "    label_free, keypoints[0],\n",
    "    stained, keypoints[1],\n",
    "    filtered_matches[:20],\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    matchesThickness=5\n",
    ")\n",
    "print(f\"Matches: {len(filtered_matches)}\")\n",
    "show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allineamento dell'immagine con RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = extract_points(filtered_matches, keypoints)\n",
    "warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "aligned_stained = apply_ransac_transform(stained, warp_matrix, shape=label_free.shape)\n",
    "aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "aligned_stained_clahe = apply_clahe(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_equalized, aligned_stained_equalized)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_clahe, \"Non colorata\", aligned_stained_clahe, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crea GIF (temporaneo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "# Define parameters\n",
    "duration = 0.5  # seconds\n",
    "frames = 2\n",
    "fps = frames / duration\n",
    "\n",
    "fig, ax = plt.subplots(figsize=STD_FIGSIZE)\n",
    "ax.axis('off')\n",
    "\n",
    "# Initialize with fully transparent aligned_stained (alpha=0)\n",
    "blend_init = cv2.addWeighted(label_free, 1.0, aligned_stained, 0.0, 0)\n",
    "im = ax.imshow(cv2.cvtColor(blend_init, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def update(frame):\n",
    "    alpha = 0 if frame == 0 else 1\n",
    "    blended = cv2.addWeighted(label_free, 1 - alpha, aligned_stained, alpha, 0)\n",
    "    im.set_data(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=frames, interval=1000/fps, blit=True)\n",
    "ani.save('fade.gif', writer='pillow', fps=fps)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contorni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength = 1\n",
    "blur_label_free = blur_image(label_free_gray, strength=strength)\n",
    "blur_stained = blur_image(stained_gray, strength=strength)\n",
    "blur_aligned_stained = blur_image(aligned_stained_gray, strength=strength)\n",
    "\n",
    "# 5. Create a black background\n",
    "height, width = label_free_gray.shape\n",
    "contour_mask_blur_label_free = np.zeros((height, width), dtype=np.uint8)\n",
    "contour_mask_blur_stained = np.zeros((height, width), dtype=np.uint8)\n",
    "contour_mask_blur_aligned_stained = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "# 6. Draw contours in white\n",
    "cv2.drawContours(contour_mask_blur_label_free, compute_countours(blur_label_free), contourIdx=-1, color=255, thickness=1)\n",
    "cv2.drawContours(contour_mask_blur_stained, compute_countours(blur_stained), contourIdx=-1, color=255, thickness=1)\n",
    "cv2.drawContours(contour_mask_blur_aligned_stained, compute_countours(blur_aligned_stained), contourIdx=-1, color=255, thickness=1)\n",
    "\n",
    "intersection_original = cv2.bitwise_and(contour_mask_blur_label_free, contour_mask_blur_stained)\n",
    "intersection_aligned = cv2.bitwise_and(contour_mask_blur_label_free, contour_mask_blur_aligned_stained)\n",
    "\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata\", cmap='gray')\n",
    "show_side_images(contour_mask_blur_label_free, \"Contorni non colorata\", contour_mask_blur_stained, \"Contorni colorata\", cmap='gray')\n",
    "show_side_images(contour_mask_blur_label_free, \"Contorni non colorata\", contour_mask_blur_aligned_stained, \"Contorni colorata allineata\", cmap='gray')\n",
    "show_side_images(intersection_original, \"Intersezione contorni originali\", intersection_aligned, \"Intersezione contorni allineati\", cmap='gray')\n",
    "\n",
    "zoomed_countour_mask_1 = cv2.resize(label_free_gray, (0, 0), fx=2, fy=2)[800:1600, 800:1600]\n",
    "zoomed_countour_mask_2 = cv2.resize(aligned_stained_gray, (0, 0), fx=2, fy=2)[800:1600, 800:1600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "blur_label_free = cv2.GaussianBlur(label_free_gray, (5, 5), 0)\n",
    "blur_stained = cv2.GaussianBlur(stained_gray, (5, 5), 0)\n",
    "blur_aligned_stained = cv2.GaussianBlur(aligned_stained_gray, (5, 5), 0)\n",
    "\n",
    "score, diff_map = ssim(contour_mask_blur_label_free, contour_mask_blur_aligned_stained, full=True)\n",
    "print(\"SSIM:\", score)\n",
    "\n",
    "def mutual_information(image1, image2, bins=256):\n",
    "    \"\"\"\n",
    "    image1, image2: single-channel images (e.g., grayscale, same shape)\n",
    "    bins: number of intensity bins for the histogram\n",
    "    \"\"\"\n",
    "    # Flatten the images to 1D\n",
    "    i1 = image1.flatten()\n",
    "    i2 = image2.flatten()\n",
    "    \n",
    "    # Compute 2D joint histogram\n",
    "    joint_hist, x_edges, y_edges = np.histogram2d(i1, i2, bins=bins)\n",
    "    \n",
    "    # Convert to joint probability by dividing by total number of pixels\n",
    "    joint_prob = joint_hist / np.sum(joint_hist)\n",
    "    \n",
    "    # Marginal probabilities\n",
    "    p1 = np.sum(joint_prob, axis=1)  # sum over columns -> distribution of image1\n",
    "    p2 = np.sum(joint_prob, axis=0)  # sum over rows -> distribution of image2\n",
    "\n",
    "    # Avoid log(0) by adding small epsilon\n",
    "    eps = 1e-10\n",
    "    # MI formula\n",
    "    mi = 0.0\n",
    "    for i in range(bins):\n",
    "        for j in range(bins):\n",
    "            p_ij = joint_prob[i, j]\n",
    "            if p_ij > eps:\n",
    "                mi += p_ij * np.log(p_ij / (p1[i]*p2[j] + eps) + eps)\n",
    "\n",
    "    return mi\n",
    "\n",
    "mi_value = mutual_information(label_free, aligned_stained)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(label_free_gray, aligned_stained_gray)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(label_free_clahe, aligned_stained_clahe)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(blur_label_free, blur_stained)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(blur_label_free, blur_aligned_stained)\n",
    "print(\"Mutual Information:\", mi_value)\n",
    "mi_value = mutual_information(contour_mask_blur_label_free, contour_mask_blur_aligned_stained)\n",
    "print(\"Mutual Information:\", mi_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_stained = stained\n",
    "aligned_stained_equalized = stained_equalized\n",
    "\n",
    "N = 1\n",
    "\n",
    "for i in range(N):\n",
    "    matches, keypoints = compute_sift_matches(label_free_equalized, aligned_stained_equalized)\n",
    "    filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)\n",
    "\n",
    "    drawn_matches = cv2.drawMatches(\n",
    "        label_free, keypoints[0],\n",
    "        aligned_stained, keypoints[1],\n",
    "        filtered_matches,\n",
    "        None,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "        matchesThickness=5\n",
    "    )\n",
    "\n",
    "    print(f\"Matches: {len(filtered_matches)}\")\n",
    "    #show_image(to_plot(drawn_matches), \"Corrispondenze SIFT\")\n",
    "\n",
    "    points = extract_points(filtered_matches, keypoints)\n",
    "    warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "    print(i, warp_matrix)\n",
    "    aligned_stained = apply_ransac_transform(aligned_stained, warp_matrix, shape=label_free.shape)\n",
    "    aligned_stained_gray = convert_to_gray(aligned_stained)\n",
    "    aligned_stained_equalized = equalize_image(aligned_stained_gray)\n",
    "\n",
    "difference = cv2.absdiff(label_free_gray, aligned_stained_gray)\n",
    "\n",
    "show_side_images(to_plot(label_free), \"Non colorata\", to_plot(aligned_stained), \"Colorata allineata\")\n",
    "show_side_images(label_free_gray, \"Non colorata\", aligned_stained_gray, \"Colorata allineata\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata\", aligned_stained_equalized, \"Colorata allineata\", cmap='gray')\n",
    "show_image(difference, \"Differenza assoluta tra immagini allineate\", cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo con metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(img1: np.ndarray, img2: np.ndarray, bins: int = 256) -> float:\n",
    "    \"\"\"\n",
    "    Compute the mutual information (MI) between two grayscale images.\n",
    "    \n",
    "    :param img1: First image in grayscale.\n",
    "    :param img2: Second image in grayscale.\n",
    "    :param bins: Number of histogram bins to use (256 for 8-bit images).\n",
    "    :return: Mutual information (in bits) between img1 and img2.\n",
    "    \"\"\"\n",
    "    # Convert images to 1D numpy arrays (flatten) if they are not already\n",
    "    img1 = img1.ravel()\n",
    "    img2 = img2.ravel()\n",
    "\n",
    "    # Compute the joint histogram\n",
    "    # histogram2d returns the 2D histogram and bin edges\n",
    "    joint_hist, x_edges, y_edges = np.histogram2d(img1, img2, bins=bins)\n",
    "    \n",
    "    # Normalize the joint histogram to get the joint PDF p(x,y)\n",
    "    joint_pdf = joint_hist / np.sum(joint_hist)\n",
    "    \n",
    "    # Compute the marginal PDFs p(x) and p(y)\n",
    "    p_x = np.sum(joint_pdf, axis=1)  # Sum over columns -> marginal over x\n",
    "    p_y = np.sum(joint_pdf, axis=0)  # Sum over rows -> marginal over y\n",
    "\n",
    "    # Only consider non-zero values to avoid log(0)\n",
    "    # MI = sum p(x,y)*log( p(x,y)/(p(x)*p(y)) )\n",
    "    non_zero_idxs = joint_pdf > 0\n",
    "    mi = np.sum(joint_pdf[non_zero_idxs] * \n",
    "                np.log2(joint_pdf[non_zero_idxs] / \n",
    "                        (p_x[np.newaxis].T @ p_y[np.newaxis])[non_zero_idxs]))\n",
    "    \n",
    "    return mi\n",
    "\n",
    "def calculate_ssim(img1: np.ndarray, img2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Structural Similarity Index (SSIM) between two images.\n",
    "    \n",
    "    :param img1: First image.\n",
    "    :param img2: Second image.\n",
    "    :return: SSIM value between img1 and img2.\n",
    "    \"\"\"\n",
    "    return ssim(img1, img2, data_range=img1.max() - img1.min())\n",
    "\n",
    "MODE_SIFT = 0\n",
    "MODE_ORB = 1\n",
    "\n",
    "def align(image_1, image_2, image_to_align=None, image_to_confront=None, mode=MODE_SIFT, use_lowes_ratio=False, use_euclidean_distance=False):\n",
    "    if image_to_align is None:\n",
    "        image_to_align = image_2\n",
    "    if image_to_confront is None:\n",
    "        image_to_confront = image_1\n",
    "    if mode == MODE_SIFT:\n",
    "        matches, keypoints = compute_sift_matches(image_1, image_2, use_lowes_ratio=use_lowes_ratio)\n",
    "    elif mode == MODE_ORB:\n",
    "        matches, keypoints = compute_orb_matches(image_1, image_2, use_lowes_ratio=use_lowes_ratio)\n",
    "    else:\n",
    "        raise Exception(\"Mode not supported\")\n",
    "    if use_euclidean_distance:\n",
    "        filtered_matches = filter_matches_by_euclidean_distance(matches, keypoints)\n",
    "    else:\n",
    "        filtered_matches = matches\n",
    "    points = extract_points(filtered_matches, keypoints)\n",
    "    warp_matrix = compute_ransac_transform(points[0], points[1])\n",
    "    aligned_image = apply_ransac_transform(image_to_align, warp_matrix, shape=image_1.shape)\n",
    "    blurred_aligned_image = blur_image(aligned_image, strength=1)\n",
    "    score = mutual_information(image_to_confront, blurred_aligned_image)\n",
    "    #score = calculate_ssim(image_to_confront, blurred_aligned_image)\n",
    "    return aligned_image, score\n",
    "\n",
    "highest = (None, None, None, None, 0)\n",
    "for mode in [MODE_SIFT, MODE_ORB]:\n",
    "    for use_lowes_ratio in [False, True]:\n",
    "        for use_euclidean_distance in [False, True]:\n",
    "            for image_1, image_2, name in [(label_free_gray, stained_gray, \"GRAY\"), (label_free_equalized, stained_equalized, \"EQUAL\"), (label_free_clahe, stained_clahe, \"CLAHE\")]:\n",
    "                _, score = align(image_1, image_2, image_to_align=stained_gray, image_to_confront=label_free_gray, mode=mode, use_lowes_ratio=use_lowes_ratio, use_euclidean_distance=use_euclidean_distance)\n",
    "                mode_name = \"SIFT\" if mode == MODE_SIFT else \"ORB\"\n",
    "                info = f\"{mode_name}\\tLR: {'T' if use_lowes_ratio else 'F'}\\tED: {'T' if use_euclidean_distance else 'F'}\"\n",
    "                print(f\"{info}\\t{name}\\tSCORE: {score}\")\n",
    "                if score > highest[4]:\n",
    "                    highest = (name, mode_name, use_lowes_ratio, use_euclidean_distance, score)\n",
    "print(f\"BEST - Image: {highest[0]} - Mode: {highest[1]} - Lowe's Ratio: {highest[2]} - Euclidean Distance: {highest[3]} - SCORE: {highest[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipLimits = [10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0]\n",
    "tileGridSizes = [(4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12)]\n",
    "\n",
    "highest = (None, None, 0)\n",
    "for clipLimit in clipLimits:\n",
    "    for tileGridSize in tileGridSizes:\n",
    "        label_free_clahe = apply_clahe(label_free_gray, clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "        stained_clahe = apply_clahe(stained_gray, clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "        _, score = align(label_free_clahe, stained_clahe, image_to_align=stained_gray, image_to_confront=label_free_gray, mode=MODE_ORB, use_lowes_ratio=False, use_euclidean_distance=True)\n",
    "        print(f\"CLAHE\\tCL: {clipLimit}\\tTGS: {tileGridSize}\\tSCORE: {score}\")\n",
    "        if score > highest[2]:\n",
    "            highest = (clipLimit, tileGridSize, score)\n",
    "print(f\"BEST - CL: {highest[0]} - TGS: {highest[1]} - SCORE: {highest[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipLimits = [2.0, 14.0]\n",
    "tileGridSizes = [(8, 8)]\n",
    "\n",
    "label_free_clahe_0 = apply_clahe(label_free_gray, clipLimit=clipLimits[0], tileGridSize=tileGridSizes[0])\n",
    "label_free_clahe_1 = apply_clahe(label_free_gray, clipLimit=clipLimits[1], tileGridSize=tileGridSizes[0])\n",
    "show_side_images(label_free_clahe_0, \"Non colorata CLAHE 2.0 (8, 8)\", label_free_clahe_1, \"Non colorata CLAHE 14.0 (8, 8)\", cmap='gray')\n",
    "show_side_images(label_free_equalized, \"Non colorata CLAHE equalizzata\", label_free_clahe_1, \"Non colorata CLAHE 14.0 (8, 8)\", cmap='gray')\n",
    "stained_clahe_0 = apply_clahe(stained_gray, clipLimit=clipLimits[0], tileGridSize=tileGridSizes[0])\n",
    "stained_clahe_1 = apply_clahe(stained_gray, clipLimit=clipLimits[1], tileGridSize=tileGridSizes[0])\n",
    "show_side_images(stained_clahe_0, \"Colorata CLAHE 2.0 (8, 8)\", stained_clahe_1, \"Colorata CLAHE 14.0 (8, 8)\", cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualStaining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
